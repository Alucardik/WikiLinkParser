# Чекин Игорь, Сервис-ориентированные архитектуры, Домашнее задание 5

## Общая структура проекта

В папке `WikiLinkParser` содержатся все основные файлы приложения (в `client-js` содержится `React.JS` веб-клиент, но, к сожалению, не удалось привязать рабочий rpc к нему, не стоит обращать на нее внимание).  В подпапке `server` находятся файлы grpc сервера, перенаправляющих запросы клиентов в очередь, в папке `client` - простой консольный grpc клиент, в `worker` - код воркера, который занимается непосредственным парсером страниц. Реализован паттерн очередь задач через брокер сообщений `RabbitMQ`, при этом воркер сам по себе работает конкуррентно.

Для локального запуска сервера необходимо наличие `go` версии `1.17 - 1.18`. Требуется перейти в папку `WikiLinkParser` и ввести команду `go run .`
Локальный запуск клиента: `go run . --mode=client`, воркера - `go run . --mode=worker`. Соответсвующие докеробразы:
1. [Воркер](https://hub.docker.com/layers/202206134/alucardik/soa-images/WikiLinkParser-worker/images/sha256-2562fa51b0cbb9ac880c43ffdf17e825417ebca398a0d068c14665c49989f511?context=repo)
2. [Сервер](https://hub.docker.com/layers/202206151/alucardik/soa-images/WikiLinkParser-server/images/sha256-52caefe1fa97f2d74cfb04e9df43ccd720af5baaf8240202ee6f279abdde6595?context=repo)
3. [Консольный Клиент](https://hub.docker.com/layers/202206117/alucardik/soa-images/WikiLinkParser-client/images/sha256-5b670ddb794690d9b7e23b944d922ec3f384a2615d39d19d0e4983cb3ee2dfdb?context=repo)

Тем не менее, рекомендуется запускать все сервисы через `docker-compose`, так как между ними уже настроены все связи. Достаточно выполнить следующие команды из корневой папки:

```bash
docker-compose build
docker up --scale worker=n
```

Где `n` - число воркеров, которые будут подключены к очереди.

## Краткое описание алгоритма

Каждую страницу воркер обрабатывает в отдельной горутине, выделяет из нее список все ссылок, проверяет их на запрещенные паттерны и форматирует, после алгоритм продолжается для каждой из ссылок (у воркера есть ограничение на количество горутин для разумности его работы). Как только была найдена новая ссылка, все остальные горутины сворачиваются, и воркер отправляет результат в очередь. (Внимание: в связи со спецификой задачи википедия может начать банить ваш адрес за большое количество запросов, рекомендуется не выбирать страницы на расстоянии больше 4-5, а также не злоупотреблять запросами)
